{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis\n",
    "\n",
    "This exercise sheet covers the following concepts.\n",
    "- $k$-Means Clustering\n",
    "- EM-Clustering\n",
    "- DBSCAN Clustering\n",
    "- Hiearchical Clustering\n",
    "\n",
    "## Libraries and Data\n",
    "\n",
    "We use the boston house price data in this exercise. The data is available as part of ```sklearn``` for [Python](http://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets).\n",
    "\n",
    "Last week we explored the boston data, this week we use it for clustering. You will apply both $k$-means clustering and DB clustering to the boston data using all fourteen columns. Functions for all clustering algorithms are available in ```sklearn``` for Python. If you experience problems with the visualizations, ensure that your ```matplotlib``` version is at least 3.0.1 and your ```seaborn``` version is at least 0.9.0. \n",
    "\n",
    "There are a couple of problems with clustering data like the boston data, that you will have to solve during this exercise.\n",
    "- The different features of the data are on different scales, which influences the results. \n",
    "- The data has fourteen dimensions. This makes visualizing the clusters difficult. You can try a dimension reduction technique like Principle Component Analysis (PCA) to get only two dimensions or use pair-wise plots. Both have advantages and drawbacks, which you should explore as part of this exercise. \n",
    "\n",
    "## $k$-Means Clustering\n",
    "\n",
    "Use $k$-Means to cluster the data and find a suitable number of clusters for $k$. Use a combination of knowledge you already have about the data, visualizations, as well as the within-sum-of-squares to determine a suitable number of clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EM Clustering\n",
    "\n",
    "(Note: EM clustering is also known as Gaussian Mixture Models and can be found in the mixture package of ```sklearn```.)\n",
    "\n",
    "Use the EM algorithm to determine multivariate clusters in the data. Determine a suitable number of clusters using the Bayesian Information Criterion (BIC). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN Clustering\n",
    "\n",
    "Use DBSCAN to cluster the data and find suitable values for $epsilon$ and $minPts$.  Use a combination of knowledge you already have about the data and visualizations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierarchical Clustering\n",
    "\n",
    "(Note: Hierarchical clustering is also known as agglomerative clustering and can be found under that name in ```sklearn```. This task requires at least ```sklearn``` version 0.22, which is still under development (October 2019). You can find guidance on how to install packages in Jupyter notebook [here](https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/) and regarding the development version of ```sklearn``` [here](https://scikit-learn.org/stable/developers/advanced_installation.html).)\n",
    "\n",
    "Use hierarchical clustering with single linkage to determine clusters within the housing data. Find a suitable cut-off for the clusters using a dendrogram. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the Clustering Results\n",
    "\n",
    "How are the clustering results different between the algorithms? Consider, e.g., the number of clusters, the shape of clusters, general problems with using the algorithms, and the insights you get from each algorithm. \n",
    "\n",
    "You may also use this to better understand the differences between the algorithms. For example, how are the results from EM clustering different/similar to the results of the $k$-Means clustering? Is there a relationship between the WSS and the BIC? How are the mean values of EM related to the centroids of $k$-Means? What is the relationship between the parameters for DBSCAN and the cut-off for the hierarchical clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
