{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "This exercise sheet covers the following concepts.\n",
    "- Classification Models\n",
    "- Comparison of Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Data\n",
    "\n",
    "Your task in this exercise is pretty straight forward: apply different classification algorithms to a data set, evaluate the results, and determine the best algorithm. You can find everything you need in ```sklearn```. \n",
    "\n",
    "We use data about dominant types of trees in forests in this exercise. The data is available as part of ```sklearn``` (requires version 0.20) for [Python](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and test data\n",
    "\n",
    "Before you can start building classifiers, you need to separate the data into training and test data. Because the data is quite large, please use 5% of the data for training, and 95% of the data for testing. Because you are selecting such a small subset, it could easily happen that not all classes are represented the same way in the training and in the test data. Use _stratified sampling_ to avoid this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, Test, Evaluate\n",
    "\n",
    "Now that training and test data are available, you can try out the classifiers from the lecture. You will notice that some classifiers may require a long amount of time for training and may, therefore, not be suitable for the analysis of this data set. \n",
    "\n",
    "Try to find a classifier that works well with the data. On this data, this means two things:\n",
    "- Training and prediction in an acceptable amount of time. Use \"less than 10 minutes\" as definition for acceptable on this exercise sheet.\n",
    "- Good prediction performance as measured with MCC, recall, precision, and F-Measure. \n",
    "\n",
    "The different classifiers have different _tuning parameters_, also known as _hyper parameters_, e.g., the depth of a tree, or the number of trees used by a random forest. Try to find good parameters to improve the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Task (will not be discussed during the exercise)\n",
    "\n",
    "Other than trying out, you can also automatically tune your hyper parameters, if you have a training, a validation, and a test set. This is also supported by ```sklearn``` [directly](https://scikit-learn.org/stable/modules/grid_search.html). You may use this to try out how such automated tuning affets your results. But beware: this can easily consume large amounts of computational capacity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
