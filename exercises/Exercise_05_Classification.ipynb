{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification\n",
        "\n",
        "This exercise sheet covers the following concepts.\n",
        "- Classification Models\n",
        "- Comparison of Models"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries and Data\n",
        "\n",
        "Your task in this exercise is pretty straight forward: apply different classification algorithms to a data set, evaluate the results, and determine the best algorithm. You can find everything you need in ```sklearn```.\n",
        "\n",
        "We use data about dominant types of trees in forests in this exercise. The data is available as part of ```sklearn``` (requires version 0.20) for [Python](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_covtype.html#sklearn.datasets.fetch_covtype)."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "from sklearn.datasets import fetch_covtype"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = fetch_covtype()\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "covtype_info = requests.get(\"http://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.info\").text\n",
        "print(covtype_info)\n",
        "\n",
        "# print(dataset.DESCR)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16,9))\n",
        "plt.rcParams[\"figure.dpi\"] = 150\n",
        "\n",
        "\n",
        "# dfcolumns = [\"Elevation\",\n",
        "#             \"Aspect\",\n",
        "#             \"Slope\",\n",
        "#             \"Horizontal_Distance_To_Hydrology\",\n",
        "#             \"Vertical_Distance_To_Hydrology\",\n",
        "#             \"Horizontal_Distance_To_Roadways\",\n",
        "#             \"Hillshade_9am\",\n",
        "#             \"Hillshade_Noon\",\n",
        "#             \"Hillshade_3pm\",\n",
        "#             \"Horizontal_Distance_To_Fire_Points\",\n",
        "#             \"Wilderness_Area\",\n",
        "#             \"Soil_Type\",\n",
        "#             \"Cover_Type\"]\n",
        "# dftarget = \"Cover_Type\"\n",
        "dataset.data.shape\n",
        "df = pd.DataFrame(dataset.data)\n",
        "df[\"target\"] = dataset.target\n",
        "sns.countplot(df[\"target\"])\n",
        "#"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training and test data\n",
        "\n",
        "Before you can start building classifiers, you need to separate the data into training and test data. Because the data is quite large, please use 5% of the data for training, and 95% of the data for testing. Because you are selecting such a small subset, it could easily happen that not all classes are represented the same way in the training and in the test data. Use _stratified sampling_ to avoid this."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "dataset_train, dataset_test, target_train, target_test = train_test_split(dataset.data, dataset.target, test_size=0.95, stratify=dataset.target)\n",
        "df_train = pd.DataFrame(dataset_train)\n",
        "# df_train['target'] = target_train\n",
        "\n",
        "df_test = pd.DataFrame(dataset_test)\n",
        "# df_test['target'] = target_test\n",
        "\n",
        "sns.countplot(target_train)\n",
        "\n",
        "sns.countplot(target_test)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train, Test, Evaluate\n",
        "\n",
        "Now that training and test data are available, you can try out the classifiers from the lecture. You will notice that some classifiers may require a long amount of time for training and may, therefore, not be suitable for the analysis of this data set.\n",
        "\n",
        "Try to find a classifier that works well with the data. On this data, this means two things:\n",
        "- Training and prediction in an acceptable amount of time. Use \"less than 10 minutes\" as definition for acceptable on this exercise sheet.\n",
        "- Good prediction performance as measured with MCC, recall, precision, and F-Measure.\n",
        "\n",
        "The different classifiers have different _tuning parameters_, also known as _hyper parameters_, e.g., the depth of a tree, or the number of trees used by a random forest. Try to find good parameters to improve the results."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## KNN"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "ss = StandardScaler()\n",
        "\n",
        "df_train_norm=ss.fit_transform(df_train)\n",
        "print(df_train_norm.mean(), df_train_norm.std())\n",
        "df_test_norm=ss.transform(df_test)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_classifier = KNeighborsClassifier(2)\n",
        "knn_classifier.fit(df_train, target_train)\n",
        "pred_knn = knn_classifier.predict(df_test)\n",
        "# knn_classifier.fit(df_train_norm, target_train)\n",
        "# pred_knn = knn_classifier.predict(df_test_norm)\n",
        "from sklearn.metrics import matthews_corrcoef, recall_score, precision_score, f1_score\n",
        "\n",
        "knn_mcc = matthews_corrcoef(target_test, pred_knn)\n",
        "knn_recall = recall_score(target_test, pred_knn, average='micro')\n",
        "knn_precision = precision_score(target_test, pred_knn, average='micro')\n",
        "knn_f1 = f1_score(target_test, pred_knn, average='micro')\n",
        "\n",
        "print(knn_mcc, knn_recall, knn_precision, knn_f1)\n",
        "knn_k = []\n",
        "knn_mcc_s = []\n",
        "knn_recall_s = []\n",
        "knn_precision_s = []\n",
        "knn_f1_s = []\n",
        "knn_classifier_s = []\n",
        "\n",
        "for i in range(1, 4):\n",
        "    knn_classifier = KNeighborsClassifier(i)\n",
        "    print(\"Training for k = \"+str(i))\n",
        "    knn_classifier.fit(df_train, target_train)\n",
        "    print(\"Testing for k = \"+str(i))\n",
        "    pred_knn = knn_classifier.predict(df_test)\n",
        "\n",
        "    knn_mcc = matthews_corrcoef(target_test, pred_knn)\n",
        "    knn_recall = recall_score(target_test, pred_knn, average='micro')\n",
        "    knn_precision = precision_score(target_test, pred_knn, average='micro')\n",
        "    knn_f1 = f1_score(target_test, pred_knn, average='micro')\n",
        "\n",
        "    knn_mcc_s.append(knn_mcc)\n",
        "    knn_recall_s.append(knn_recall)\n",
        "    knn_precision_s.append(knn_precision)\n",
        "    knn_f1_s.append(knn_f1)\n",
        "\n",
        "    knn_classifier_s.append(knn_classifier)\n",
        "\n",
        "    knn_k.append(i)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.plot(knn_k, knn_mcc_s)\n",
        "plt.plot(knn_k, knn_recall_s)\n",
        "plt.plot(knn_k, knn_precision_s)\n",
        "plt.plot(knn_k, knn_f1_s)\n",
        "plt.show()\n",
        "\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Bonus Task (will not be discussed during the exercise)\n",
        "\n",
        "Other than trying out, you can also automatically tune your hyper parameters, if you have a training, a validation, and a test set. This is also supported by ```sklearn``` [directly](https://scikit-learn.org/stable/modules/grid_search.html). You may use this to try out how such automated tuning affets your results. But beware: this can easily consume large amounts of computational capacity!"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "resources": {
        "logo-64x64": "/user/a.sujatanagarjuna/kernelspecs/python3/logo-64x64.png",
        "logo-32x32": "/user/a.sujatanagarjuna/kernelspecs/python3/logo-32x32.png"
      },
      "language": "python",
      "display_name": "Python 3",
      "argv": [
        "/opt/conda/bin/python",
        "-m",
        "ipykernel_launcher",
        "-f",
        "{connection_file}"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}